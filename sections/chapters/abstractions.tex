\chapter{Refinement approach}
In this chapter we present an abstraction procedure for the quantifier free bitvector theory (\texttt{QF\_BV}).
The approach substitutes applications of specific functions (here \texttt{bvmul}, \texttt{bvsdiv} and \texttt{bvsrem}) by \textit{abstractions} defined on the \texttt{QF\_UFBV} theory.
During the solving process, an instance's abstractions are iteratively refined until the SAT solver either returns unsatisfiability or satisfiability with sound variable assignments.

\section{Abstraction Scheme}
In the SMT-LIB standard \cite{BarFT-SMTLIB} for \texttt{QF\_BV} the functions examined in this work (i.e. \texttt{bvmul}, \texttt{bvsdiv} and \texttt{bvsrem}) support \textit{overloading} in the sense that a single function symbol like \texttt{bvmul} supports multiple ranks as multiplication for example is supported for any bitwidth.
To simplify the explanations in the following sections we will define $\texttt{bvmul}^r$ as the \texttt{bvmul} operation of rank $r$.

\begin{definition}[Approximation]
Given some theory $T=\left(\Sigma,A\right)$ and some function symbol $\texttt{op}\in\Sigma^F$ with $\mathcal{s}^F\left(\texttt{op}\right)=\sigma_1\dotsi\sigma_n\sigma$ and $n\geq1$ a $T$-approximation for \texttt{op} consists of:
\begin{itemize}
    \item A new uninterpreted function symbol $ap_{\texttt{op}}$ with $\mathcal{s}^F\left(\texttt{op}\right) = \mathcal{s}^F\left(ap_{\texttt{op}}\right)$
    \item A mapping $\mathcal{A}_{\texttt{op}}\colon \textsc{Term}^\Sigma_{\sigma_1}\times\dotsi\times\textsc{Term}^\Sigma_{\sigma_n} \to 2^{\textsc{For}^1_T}$
\end{itemize}
A $T$-approximation can therefore be written as a tuple $\left(ap_{\texttt{op}}, \mathcal{A}_{\texttt{op}}\right)$
\end{definition}
We can now define properties that a $T$-approximation might have. This will be useful to proof the correctness of our abstraction procedure later on

\begin{definition}[Sound $T$-approximation]
    \label{def:refinement_approach:abstraction_scheme:soundness}
Given some theory $T=\left(\Sigma,A\right)$ a $T$-approximation $\left(ap_{\texttt{op}}, \mathcal{A}_{\texttt{op}}\right)$ is sound iff for all
$\overline{x}\in Dom
\footnote{$Dom$ is the domain of a given function. In this case $Dom\left(\mathcal{A}_{\texttt{op}}\right) = \textsc{Term}^\Sigma_{\sigma_1}\times\dotsi\times\textsc{Term}^\Sigma_{\sigma_n}$}
\left(\mathcal{A}_{\texttt{op}}\right)$ the following property holds:\\
For all $T$-interpretation $\mathcal{I}$ with $\mathcal{I}\vDash\mathcal{A}_{\texttt{op}}\left(\overline{x}\right)$ there is also
$\mathcal{I}\vDash ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)$
\end{definition}

\begin{definition}[Complete $T$-approximation]
\label{def:refinement_approach:abstraction_scheme:completeness}
Given some theory $T=\left(\Sigma,A\right)$ a $T$-approximation $\left(ap_{\texttt{op}}, \mathcal{A}_{\texttt{op}}\right)$ is complete iff for all $\overline{x}\in Dom\left(\mathcal{A}_{\texttt{op}}\right)$ the following property holds:\\
For all $T$-interpretations $\mathcal{I}$ with $\mathcal{I}\vDash ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)$ there is also
$\mathcal{I}\vDash\mathcal{A}_{\texttt{op}}\left(\overline{x}\right)$
\end{definition}

\begin{example}
For readability let $\texttt{f} \coloneqq \texttt{mul}^{\mathbf{BV}_2\mathbf{BV}_2\mathbf{BV}_2}$ be the 2-bit multiplication function as defined in \texttt{QF\_BV}.\\
Example for a sound approximation:
\[
    \mathcal{A}_\texttt{f}\left(x_1,x_2\right) 
    \coloneqq \{
    ab_\texttt{f}\left(x_1,x_2\right) \doteq 0, \left(x_1\doteq 0 \lor x_2 \doteq 0\right)
    \}
\]
Example for a complete approximation:
\[
    \mathcal{A}_\texttt{f}\left(x_1,x_2\right) 
    \coloneqq \{
    \left(x_1\doteq 0 \lor x_2 \doteq 0\right) \implies ab_\texttt{f}\left(x_1,x_2\right) \doteq 0
    \}
\]
Example for a sound and complete approximation:
\[
\mathcal{A}_\texttt{f}\left(x_1,x_2\right) 
        \coloneqq \{
        ab_\texttt{f}\left(x_1,x_2\right) \doteq \texttt{f}\left(x_1,x_2\right)
        \}
\]
\end{example}
Essentially a sound $T$-approximation describes an under-approximation and a complete $T$-approximation describes an over-approximation of some function \texttt{op}. Using the notions defined above we can now define an abstraction scheme which iteratively refines an over-approximation until the abstraction converges into an exact description of the given function \texttt{op}.
\begin{definition}[Abstraction Scheme]
Given some theory $T=\left(\Sigma,A\right)$ and some function symbol $\texttt{op}\in\Sigma^F$ of arity greater $0$, a $T$-abstraction scheme is a finite, totally ordered set of $\ T$-approximations \[
\mathcal{AS}_{\texttt{op}} = \{ \left(ab_{\texttt{op}}, \mathcal{A}^1_{\texttt{op}}\right),\dots,\left(ab_{\texttt{op}}, \mathcal{A}^k_{\texttt{op}}\right) \}
\]
where:
\begin{itemize}
    \item For every $i\in\llbracket1,k\rrbracket$: $\mathcal{A}^i_{\texttt{op}}$ is a complete $T$-approximation of \texttt{op}
    \item $\mathcal{C}_{\texttt{op}}\left(\overline{x}\right)\coloneqq\left(\bigcup\limits_{\left(\wc,\mathcal{A}\right)\in\mathcal{AS}_{\texttt{op}}} \mathcal{A}\left(\overline{x}\right)\right)$ is a sound $T$-approximation of \texttt{op}
    \footnote{
        Just like all previous $T$-approximations $\mathcal{C}_{\texttt{op}}$ is defined as
        $\mathcal{C}_{\texttt{op}}\colon \textsc{Term}^\Sigma_{\sigma_1}\times\dotsi\times\textsc{Term}^\Sigma_{\sigma_n} \to 2^{\textsc{For}^1_T}$ for a function symbol \texttt{op} of rank $\sigma_1\dotsi\sigma_n\sigma$
    }
\end{itemize}
\end{definition}

\begin{lemma}[Completeness of Abstraction Schemes]
    \label{lemma:refinement_approach:abstraction_scheme:as_completeness}
Given some $T$-approximation scheme 
$\mathcal{AS}_{\texttt{op}} = \{ \left(ab_{\texttt{op}}, \mathcal{A}^1_{\texttt{op}}\right),\dots,\left(ab_{\texttt{op}}, \mathcal{A}^k_{\texttt{op}}\right) \}$
with the properties defined above we can show that:\\
$\mathcal{C}_{\texttt{op}}$ is a complete $T$-approximation of \texttt{op}.
\begin{proof}
Let $\overline{x}$ be an arbitrary input vector for \texttt{op}.\\
By definition we know that for any $T$-interpretation $\mathcal{I}$ with $\mathcal{I} \vDash ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)$ there is also $\mathcal{I} \vDash \mathcal{A}^i_{\texttt{op}}\left(\overline{x}\right)$ for all $i\in\llbracket1,k\rrbracket$ as all approximations $\mathcal{A}^i_{\texttt{op}}$ are complete.\\
Therefore,
\[
    \mathcal{I} \vDash \bigcup\limits_{\left(\wc,\mathcal{A}\right)\in\mathcal{AS}_{\texttt{op}}} \mathcal{A}\left(\overline{x}\right)
    \text{ (i.e. }\mathcal{I} \vDash \mathcal{C}_{\texttt{op}}\left(\overline{x}\right)\text{)}
\]
which implies that $\mathcal{C}_{\texttt{op}}$ is a complete $T$-approximation, too.
\end{proof}
\end{lemma}

\begin{lemma}[Soundness/Completeness through Implication]
    \label{lemma:refinement_approach:abstraction_scheme:implication}
    Given some theory $T=\left(\Sigma,A\right)$ and a $T$-approximation $\left(ap_{\texttt{op}}, \mathcal{A}_{\texttt{op}}\right)$\\
    If for all interpretations $\mathcal{I}$ and all $\overline{x}\in Dom\left(\mathcal{A}_{\texttt{op}}\right)$
    \[
        \mathcal{A}_{\texttt{op}}\left(\overline{x}\right) \implies ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)
    \]
    then $\left(ap_{\texttt{op}}, \mathcal{A}_{\texttt{op}}\right)$ is sound.\\
    If for all interpretations $\mathcal{I}$ and all $\overline{x}\in Dom\left(\mathcal{A}_{\texttt{op}}\right)$
    \[
        ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right) \implies \mathcal{A}_{\texttt{op}}\left(\overline{x}\right)
    \]
    then $\left(ap_{\texttt{op}}, \mathcal{A}_{\texttt{op}}\right)$ is complete.
    \begin{proof}
        The proof follows directly from definitions \ref{def:refinement_approach:abstraction_scheme:soundness} (\ref{def:refinement_approach:abstraction_scheme:completeness}).\\
        Given for some formula the soundness (completeness) formula above holds for all $\mathcal{I}$ and $\overline{x}$:\\
        For any interpretation $\mathcal{I}$ where
            $\mathcal{I}\nvDash\mathcal{A}_{\texttt{op}}\left(\overline{x}\right)$
            ($\mathcal{I}\nvDash ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)$)
            the definition for soundness (completeness) is already fulfilled.\\
        In case for some interpretation $\mathcal{I}$ it holds that 
            $\mathcal{I}\vDash\mathcal{A}_{\texttt{op}}\left(\overline{x}\right)$
            ($\mathcal{I}\vDash ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)$)
        then we know through the formula above that
            $\mathcal{I}\vDash ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)$
            ($\mathcal{I}\vDash\mathcal{A}_{\texttt{op}}\left(\overline{x}\right)$)
        which implies that the approximation is by definition sound (complete).


    \end{proof}
\end{lemma}

\begin{theorem}[Correctness of abstraction approach]
\label{theorem:abstractions:scheme:equivalence}
Let $T=\left(\Sigma,A\right)$ be some signature with $\texttt{op}\in\Sigma^F$, $\mathcal{s}^F\left(\texttt{op}\right)=\sigma_1\dotsi\sigma_n\sigma$ and $n\geq1$.\\
Let further $\Phi$ be an arbitrary $\Sigma$-formula containing some function application $\texttt{op}\left(\overline{x}\right)$.\\
Given some term $t\in\textsc{Term}_\sigma^\Sigma$ we define $\Phi\left[\texttt{op}\left(\overline{x}\right)\mapsto t \right]$ as the formula where $\texttt{op}\left(\overline{x}\right)$ was replaced by $t$ in $\phi$.\\
For any $T$-abstraction scheme $\mathcal{AS}_{\texttt{op}}$ with function symbol $ab_{\texttt{op}}$ the following property holds:\\
There exists a $T$-interpretation $\mathcal{I}_{\Phi}$ that is a $T$-model for $\Phi$ iff there exists a $T$-interpretation $\mathcal{I}_{\mathcal{A}}$ that is a $T$-model for 
\[
\Psi \coloneqq \Phi\left[ \texttt{op}\left(\overline{x}\right) \mapsto ab_{\texttt{op}}\left(\overline{x}\right) \right] \land \bigwedge\limits_{\left(\wc,\mathcal{A}\right)\in\mathcal{AS}_{\texttt{op}}} \mathcal{A}\left(\overline{x}\right)
\]
\begin{proof}
The theorem will be proved in 2 directions. For each direction we will construct a suitable interpretation given the premise interpretation.
\begin{itemize}
    \item[$\Rightarrow$] Let $\mathcal{I}_{\Phi}$ be a $T$-model for $\Phi$.\\
        We will now build a model $\mathcal{I}_{\mathcal{A}}$ by extending $\mathcal{I}_{\Phi}$ so that $\mathcal{I}_\mathcal{A}\left(ab_{\texttt{op}}\left(\overline{x}\right)\right)$
        evaluates to $\mathcal{I}_{\Phi}\left(\texttt{op}\left(\overline{x}\right)\right)$.\\
        We then know that $\mathcal{I}_{\mathcal{A}} \vDash ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)$
        and the completeness proofed in Lemma \ref{lemma:refinement_approach:abstraction_scheme:as_completeness} tells us that thereby
        $\mathcal{I}_{\mathcal{A}} \vDash \mathcal{A}_{\texttt{op}}\left(\overline{x}\right)$.
        Therefore 
        \[
            \mathcal{I}_{\mathcal{A}} \vDash\Phi\left[ \texttt{op}\left(\overline{x}\right) \mapsto ab_{\texttt{op}}\left(\overline{x}\right) \right] \land \bigwedge\limits_{\left(\wc,\mathcal{A}\right)\in\mathcal{AS}_{\texttt{op}}} \mathcal{A}\left(\overline{x}\right)
        \]
    \item[$\Leftarrow$]  Let $\mathcal{I}_{\mathcal{A}}$ be a $T$-model for $\Psi$.\\
        The abstraction scheme definition tells us that
        \[
            \mathcal{I}_{\mathcal{A}} \vDash \bigwedge\limits_{\left(\wc,\mathcal{A}\right)\in\mathcal{AS}_{\texttt{op}}} \mathcal{A}\left(\overline{x}\right)
        \] 
        also yields $\mathcal{I}_{\mathcal{A}} \vDash ap_{\texttt{op}}\left(\overline{x}\right) \doteq \texttt{op}\left(\overline{x}\right)$ through the soundness property.\\
        This implies that $\mathcal{I}_{\mathcal{A}} \vDash \Phi$.
\end{itemize}
\end{proof}
\end{theorem}

\paragraph{Abstraction approach}
In the following sections abstraction schemes for three function symbols of the \texttt{QF\_BV} theory will be presented.
In order to proof that the abstractions are actually valid we will:
\begin{itemize}
    \item[(A)] Proof the completeness of any approximation proposed
    \item[(B)] Proof the soundness of each abstraction scheme
\end{itemize}
As can be seen in Theorem \ref{theorem:abstractions:scheme:equivalence} this will enough to proof that the abstraction schemes are correct.\\
The abstractions can then be used to build a decision procedure like the one described in Algorithm \ref{algorithm:refinement_approach:abstraction_scheme:refinement}

\begin{algorithm}
    \caption{Decision procedure for QF\_BV abstractions}
    \begin{algorithmic}
    \label{algorithm:refinement_approach:abstraction_scheme:refinement}
    \REQUIRE $\phi \in \textsc{For}^1_{QF\_BV}$
    \STATE abstractions$ \leftarrow \langle\rangle$
    \STATE operations$ \leftarrow \langle\rangle$
    \FORALL{$\texttt{op}\in\Sigma^F$}
        \IF{\texttt{op} needs refinement}
            \FORALL{$\texttt{op}\left(\overline{x}\right)$ in $\phi$}
                \STATE $\phi \leftarrow \phi\left[\texttt{op}\left(\overline{x}\right) \mapsto ab_\texttt{op}\left(\overline{x}\right)\right]$
                \STATE abstractions.push$\left(\mathcal{AS}_\texttt{op}\right)$
                \STATE operations.push$\left( \texttt{op}\left(\overline{x}\right) \right)$
            \ENDFOR
        \ENDIF
    \ENDFOR
    \STATE \texttt{ADD\_CLAUSES($\phi$)}
    \LOOP
    \STATE $r \leftarrow $\texttt{SAT($\phi$)}
    \IF{\NOT $r$}
        \PRINT unsat
    \ELSE
        \STATE correct $\leftarrow \TRUE$
        \FORALL{$\texttt{op}\left(\overline{x}\right)$ in operations}
            \IF{\NOT $\texttt{op}\left(\overline{x}\right)$ assignment is correct}
                \STATE correct $\leftarrow \FALSE$
            \ENDIF
        \ENDFOR
        \IF{correct}
            \PRINT sat
        \ELSE
            \FORALL{$\mathcal{AS}$ in abstractions}
                \STATE \texttt{ADD\_CLAUSES($\mathcal{AS}$.pop())}
                \COMMENT{Add next approximation to for $\mathcal{AS}$ to instance}
            \ENDFOR
        \ENDIF
    \ENDIF
    \ENDLOOP
    \end{algorithmic}
\end{algorithm}

\section{Abstracting \texttt{bvmul}}
The abstraction scheme for \texttt{bvmul} is devided into four stages:
The first stage describes the behaviour of \texttt{bvmul} for various common cases (like factors 0 and 1);
the second stage defines intervals for the result value given the intervals of the multiplication factors;
the third stage introduces relations between \texttt{bvmul} and other functions (specifically \texttt{bvsdiv} and \texttt{bvsrem});
the fourth stage finally adds full multiplication for certain intervals of the factors.

\paragraph{Overflow detection}
The \texttt{bvmul} function essentially behaves just like \enquote{regular} integer multiplication for any input value
which doesn't produce an overflow.
Upon overflow however, \texttt{bvmul} oftentimes behaves strangely as behaviour in modern C compilers is usually undefined
and behaviour in SMT-LIB - though well defined - is difficult to model mathematically the same way it is done for \enquote{regular} multiplication.
For many of the abstractions proposed in this chapter it is therefore essential to detect overflows.
As we have already seen in section \ref{par:related_work:boolector} Boolector supports a predicate to detect signed and unsigned multiplication overflows.
The issue with this predicate however is that already here we have to calculate the first $w+1$ steps of multiplication given bitvectors of width $w$.
This is particularly cumberstone when one only event wants to abstract the first $w$ steps of multiplication like we do.
Therefore a predicate with no need for a multiplication unit was needed.
Obviously such a predicate without a multiplication unit, while complete, might not be sound - i.e. while every overflow might be detected,
this predicate might detect more overflows than actually exist.
The methodology used here is based on \cite{Warren-HackersDelight} where another methodology for detecting overflows by counting the leading bits (ones or zeros)
is proposed:
The predicate ensures that there are at least $w+2$ leading bits for any multiplication of 2 negative numbers and at least $w+1$ leading bits for any other multiplication.
While excluding a few cases with no overflows this predicate is never true for a pair of factors which results in an overflow.
The corresponding predicate is defined in Definition \ref{def:refinement_approach:bvmul:noov} and will be used on multiple occations in the following sections.
\begin{definition}[$noov$ predicate]
    We define a Boolean function $noov: \{0,1\}^w \times \{0,1\}^w \rightarrow \{0,1\}$ with
    \label{def:refinement_approach:bvmul:noov}
    \begin{align*}
        noov\left(a, b\right)
        = &\bigvee\limits_{n=0}^{w-1}
            \left(
            \bigwedge\limits_{i=0}^{n} \neg a[w-i-1]
            \land
            \bigwedge\limits_{i=n}^{w-1} \neg b[i]
            \right) \lor\\
            &\bigvee\limits_{n=0}^{w-1}
            \left(
            \bigwedge\limits_{i=0}^{n} a[w-i-1]
            \land
            \bigwedge\limits_{i=n}^{w-1} \neg b[i]
            \right) \lor\\
            &\bigvee\limits_{n=0}^{w-1}
            \left(
            \bigwedge\limits_{i=0}^{n} \neg a[w-i-1]
            \land
            \bigwedge\limits_{i=n}^{w-1} b[i]
            \right) \lor\\
            &\bigvee\limits_{n=0}^{w-2}
            \left(
            \bigwedge\limits_{i=0}^{n} a[w-i-2]
            \land
            \bigwedge\limits_{i=n}^{w-2} b[i]
            \land a[w-1]
            \land b[w-1]
            \right)
    \end{align*}
\end{definition}

\subsection{Simple cases}
\label{subsec:refinement_approach:bvmul:simple}
For a multiplication instance $ab_\texttt{bvmul}\left(x,y\right)$ of factors $x$ and $y$ with bitwidth $w$ we define the following constraints:
\begin{flalign}
    \left(x \doteq 0\right) &\Rightarrow && \left(ab_\texttt{bvmul}\left(x,y\right) \doteq 0\right)
        &\label{align:refinement_approach:bvmul:simple:zero1}\\
    \left(y \doteq 0\right) &\Rightarrow && \left(ab_\texttt{bvmul}\left(x,y\right) \doteq 0\right)
        &\label{align:refinement_approach:bvmul:simple:zero2}\\
    \left(x \doteq 1\right) &\Rightarrow && \left(ab_\texttt{bvmul}\left(x,y\right) \doteq y\right)
        &\label{align:refinement_approach:bvmul:simple:one1}\\
    \left(y \doteq 1\right) &\Rightarrow && \left(ab_\texttt{bvmul}\left(x,y\right) \doteq x\right)
        &\label{align:refinement_approach:bvmul:simple:one2}\\
    \left(x \doteq -1\right) &\Rightarrow && \left(ab_\texttt{bvmul}\left(x,y\right) \doteq -y\right)
        &\label{align:refinement_approach:bvmul:simple:neg1}\\
    \left(y \doteq -1\right) &\Rightarrow && \left(ab_\texttt{bvmul}\left(x,y\right) \doteq -x\right)
        &\label{align:refinement_approach:bvmul:simple:neg2}\\
    noov(x,y) &\Rightarrow && 
        \left( \neg x[w-1] \land \neg y[w-1] \right)
            \Rightarrow
            \left(ab_\texttt{bvmul}\left(x,y\right) \geq 0\right)
                &\label{align:refinement_approach:bvmul:simple:bothPos}\\
            && \land & \left( \neg x[w-1] \land y[w-1] \right)
            \Rightarrow
            \left(ab_\texttt{bvmul}\left(x,y\right) < 0\right)
                &\label{align:refinement_approach:bvmul:simple:oneNeg1}\\
            && \land & \left( x[w-1] \land \neg y[w-1] \right)
            \Rightarrow
            \left(ab_\texttt{bvmul}\left(x,y\right) < 0\right)
                &\label{align:refinement_approach:bvmul:simple:oneNeg2}\\
            && \land  & \left( x[w-1] \land y[w-1] \right)
            \Rightarrow
            \left(ab_\texttt{bvmul}\left(x,y\right) > 0\right)
                &\label{align:refinement_approach:bvmul:simple:bothNeg}\\
\end{flalign}
Equations (\ref{align:refinement_approach:bvmul:simple:zero1}) and (\ref{align:refinement_approach:bvmul:simple:zero2}) define the multiplication cases where one factor is zero and (\ref{align:refinement_approach:bvmul:simple:one1}) as well as (\ref{align:refinement_approach:bvmul:simple:one2}) define the cases where one factor is 1.
Furthermore (\ref{align:refinement_approach:bvmul:simple:neg1}) and (\ref{align:refinement_approach:bvmul:simple:neg2}) define the negation cases.\\
Additionally we can make statements about the result's sign whenever we can be certain that no overflow is going to happen.
For the cases where no overflow happens the sign behaviour of bitvector multiplication corresponds to the \enquote{common} sign behaviour and can therefore be split into 3 distinct cases:
\begin{itemize}
    \item Both factors are non-negative producing a non-negative result (\ref{align:refinement_approach:bvmul:simple:bothPos})
    \item Both factors are negative producing a positive result
    (\ref{align:refinement_approach:bvmul:simple:bothNeg})
    \item One of the factors is negative producing a negative result (\ref{align:refinement_approach:bvmul:simple:oneNeg1}), (\ref{align:refinement_approach:bvmul:simple:oneNeg2})
\end{itemize}
Additionally all cases where one of the two factors is a power of 2 can covered by constraints like (\ref{align:refinement_approach:bvmul:simple:pow2}) for all $i\in\llbracket 1,w \rrbracket$ and for $x$ and $y$ symmetrically:
\begin{flalign}
    \bigwedge\limits_{j \neq i} \neg x\left[j\right] \land x\left[i\right] \implies \left( ab_\texttt{bvmul}\left(x,y\right) \doteq shl\footnotemark\left( y, i \right)  \right)
    \label{align:refinement_approach:bvmul:simple:pow2}
\end{flalign}
\footnotetext{The left shift function}

\paragraph{Completeness} The completeness of this abstraction is a direct consequence of Lemma \ref{lemma:refinement_approach:abstraction_scheme:implication}
as it can be easily checked that all formulae presented above (which specifically omitted any statements about difficult overflow cases) are implications of
$ab_{\texttt{bvmul}}\left(x,y\right) \doteq \texttt{bvmul}\left(x,y\right)$.




\subsection{Most significant digit based intervals}
\label{subsec:refinement_approach:bvmul:msd}
Using the factors most significant digits, intervals of the factors can be defined which in turn can be used to assert intervals of the multiplication's result.
In a first step the signed multiplication $r\coloneqq ab_\texttt{bvmul}\left(x,y\right)$ is transformed into its unsigned version with doubled bitwidth by using the absolute values:
\begin{flalign*}
    x_2^+ \doteq \texttt{ITE(}  & x[w-1],&\\
                                & -sext\footnotemark\left(x,w\right)&\\
                                & sext\left(x,w\right)\texttt{)}&\\
    y_2^+ \doteq \texttt{ITE(}  & y[w-1],&\\
                                & -sext\left(y,w\right),&\\
                                & sext\left(y,w\right)\texttt{)}&\\
    r'_2 \doteq \texttt{ITE(} & x[w-1] \oplus y[w-1],&\\
                                & -umul(x_2^+,y_2^+), &\\
                                & umul(x_2^+,y_2^+) \texttt{)}&\\
\end{flalign*}
\footnotetext{The sign extension function}
By asserting equality of the multiplication result $r$ and $r'_2\left[w:\right]$ it is then possible to reason about the results of $r^+_2\coloneqq umul(x_2^+,y_2^+)$ through bit shifting:
If $i$ is the most significant digit of $x'$ then $2^i\leq x' < 2^{i+1}$. Therefore $2^i*y' \leq r^+_2 < 2^{i+1}*y'$.
We now define a predicate $msd(x,i)$ which is true iff the most significant digit of $x$ is i.
\begin{definition}{$msd(x,i)$}

For some bitvector $x$ of width $w$ and an $i \in \llbracket 0,w \rrbracket$ we define:
\[
msd(x,i) \coloneqq  x[i]\land\bigwedge\limits_{j=i+1}^{w-1} \neg x[j]    
\]
\end{definition}

The previously presented results give rise to the following abstraction which must again distinguish overflow from no-overflow cases.
For this we will initally use a double bit width (i.e. $2*w$ width) unsigned multiplication function as well as double bit width lower and upper bounds as defined below.
We can then compare the necessary number of bits depending on the result of $noov$: If an overflow is possible we must compare the version with $2*w$ bits,
otherwise the $w$ bit version can be used for comparison.
\begin{flalign*}
    lower(a, b, n)\coloneqq&
    \begin{cases}
        \texttt{ITE(} msd(a,0), b, 0 \texttt{)} & n=0\\
        \texttt{ITE(} msd(a,n), shl\left(b, n\right), lower(a, b, n-1) \texttt{)} & else
    \end{cases}
\\
    upper(a, b, n)\coloneqq&
    \begin{cases}
        shl\left(b,1\right) & n=0\\
        \texttt{ITE(} msd(a,n), shl\left(b, n+1\right), upper(a, b, n-1) \texttt{)} & else\\
    \end{cases}
\\
    noov(x',y') \Rightarrow& lower(x^+_2,y^+_2,w)[w:] \leq r^+_2\left[w:\right] \leq upper(x^+_2,y^+_2,w)[w:]
\\
     noov(x',y') \Rightarrow& lower(y^+_2,x^+_2,w)[w:] \leq r^+_2\left[w:\right] \leq upper(y^+_2,x^+_2,w)[w:]
\\
    \neg noov(x',y') \Rightarrow& lower(x^+_2,y^+_2,w) \leq r^+_2 \leq upper(x^+_2,y^+_2,w)
\\
     \neg noov(x',y') \Rightarrow& lower(y^+_2,x^+_2,w) \leq r^+_2 \leq upper(y^+_2,x^+_2,w)
\end{flalign*}
Note that while $lower$ and $upper$ seem to be functions here they can be unrolled into consecutive \texttt{ITE} statements when adding the bounds to the instance to easen the solver's decision process.

\paragraph{Completeness}
Given the distinction made between overflow and no-overflow cases and the treatment of overflow cases through the use of a doubled bitwidth multiplication
it can again easily be checked that these constraints are direct implications of $ab_{\texttt{bvmul}}\left(x,y\right) \doteq \texttt{bvmul}\left(x,y\right)$.
Therefore, this approximation is again complete as seen in Lemma \ref{lemma:refinement_approach:abstraction_scheme:implication}.


\subsection{Relations to other functions}
\label{subsec:refinement_approach:bvmul:relations}
Additionally to the previously described abstractions which all focused on relations between inputs and outputs of the specific function
one can also look at relations between the given instruction invocation $ab_\texttt{bvmul}(\cdot,\cdot)$ and other invocations of the same or other instructions.
This provides the solver with more high-level information and can therefore be useful in cases where relations between multiple instruction calls already lead to a contradiction without looking at the implementation details of the instructions.

For the multiplication instruction $ab_\texttt{bvmul}(x_2,y_2)$ with $x_2$ and $y_2$ the double bitwidth ($2*w$) versions of $x$ and $y$ we propose the following abstractions,
which become particularly interesting when combined with similar abstractions for the  \texttt{bvsrem} and \texttt{bvsdiv} function as described in the following sections:
\begin{flalign*}
    ab_\texttt{bvmul}(x_2,y_2) \doteq& ab_\texttt{bvmul}(y_2,x_2)\\
    x_2 \doteq 0 \lor y_2 \doteq& ab_\texttt{bvsdiv}(ab_\texttt{bvmul}(x_2,y_2),x_2)\\
    y_2 \doteq 0 \lor x_2 \doteq& ab_\texttt{bvsdiv}(ab_\texttt{bvmul}(x_2,y_2),y_2)\\
\end{flalign*}
For every bit width $w'<2*w$ which appears in a given problem instance and its abstractions we can further assert that:
\[
    ab_\texttt{bvmul}(x_2,y_2)[w':] \doteq ab_\texttt{bvmul}(x_2[w':],y_2[w':])
\]
\[
    ab_\texttt{bvmul}(x_2,y_2)[w':] \doteq ab_\texttt{bvmul}^{w'}(y_2[w':],x_2[w':])
\]
and for:
\[
    x' \coloneqq sext\left(x_2\left[\left\lfloor \frac{w'}{2} \right\rfloor:\right], w'-\left\lfloor \frac{w'}{2} \right\rfloor\right)
\]\[
    y' \coloneqq sext\left(y_2\left[\left\lfloor \frac{w'}{2} \right\rfloor:\right], w'-\left\lfloor \frac{w'}{2} \right\rfloor\right)
\]
we assert that:
\[
   ab_\texttt{bvmul}(x',y') \doteq ab_\texttt{bvmul}(y',x')
\]
\[
    y'\doteq 0 \lor x' \doteq ab_\texttt{bvsdiv}\left(ab_\texttt{bvmul}(x',y'),y'\right)
\]
\[
    x'\doteq 0 \lor y' \doteq ab_\texttt{bvsdiv}\left(ab_\texttt{bvmul}(x',y'),x'\right)
\]
Essentially all these relations between various multiplication and division applications are all based
on properties defined in the C standard \cite{ISO14882:2011} for multiplication and division.\\
The only challenge of this abstraction was to formulate the constraints so that they are even complete for overflow cases.\\
A naive approach would simply encode the constraints in single bitwidth $w$.
This however, turns out to be problematic as the properties listed above do not hold for overflow cases that (according to the C standard) 
result in undefined behaviour and most certainly not in above constraints being respected.
Therefore an approach with doubled bitwidth $2*w$ was used while encoding the constraints.

\paragraph{Completeness}
The completeness of this abstraction is a direct consequence of there not happening any overflows within the functions used (as explained above due to the doubled bitwidth)
and all assertions being well-known properties of machine multiplication and division even defined in the C standard.

\subsection{Full multiplication}
\label{subsec:refinement_approach:bvmul:fullmul}
In a last step full multiplication on a per-interval basis is added as constraint.
Given an SMT instance containing some multiplication $\texttt{bvmul}\left(x,y\right)$ is still satisfiable after having been passed through refinement steps
\ref{subsec:refinement_approach:bvmul:simple} to \ref{subsec:refinement_approach:bvmul:relations}, the solver returns a counterexample with assignments for $x$ and $y$.
We then look up the most significant bit $i$ of $x$'s assignment and assert that:
\[
    msd\left(x,i\right) \implies ab_{\texttt{bvmul}}\left(x,y\right) \doteq \texttt{bvmul}\left(x,y\right)
\]
\paragraph{Completeness and Soundness}
For a multiplication of bitwidth $w$ the approximation is obviously complete and it even becomes sound once this assertion has been made
for all $i\in\llbracket 0,w-1\rrbracket$. It is also easy to see that the maximum number of refinement steps necessary here is bounded by $w$.

\section{Abstracting \texttt{bvsdiv}}
Just like multiplication \texttt{bvsdiv} is a rather costly function in terms of formulae needed for its representation.
Furthermore concepts very similar to those used for abstracting \texttt{bvmul} can be reused as an abstraction approach for \texttt{bvsdiv}.
We will therefore present a very similar four step abstraction approach for \texttt{bvsdiv} below.\\
Note that \texttt{bvsdiv} can only overflow in the case of dividing the minimum integer ($10^{w-1}$ in binary) by $-1$.
In SMT-LIB this results (again) in the minimum integer.

\subsection{Simple cases}
\label{subsec:refinement_approach:bvsdiv:simple}
For some division $\texttt{bvsdiv}\left(x,y\right)$ of bitwidth $w$ a certain number of simple cases can again be encoded as a first abstraction step:
\begin{flalign}
    \left(y \doteq 0\right) \implies
        &ab_{\texttt{bvsdiv}}\left(x,y\right) \doteq \texttt{ITE}\left(a<0, 1, x\right)&\label{align:refinement_approach:bvsdiv:simple:div0}\\
    \left(y \doteq 1\right) \implies
        &ab_{\texttt{bvsdiv}}\left(x,y\right) \doteq x&\label{align:refinement_approach:bvsdiv:simple:div1}\\
    \left(y \doteq x\right) \implies
        &ab_{\texttt{bvsdiv}}\left(x,y\right) \doteq 1&\label{align:refinement_approach:bvsdiv:simple:divx}\\
    \left(y \doteq -1\right) \implies
        &ab_{\texttt{bvsdiv}}\left(x,y\right) \doteq -x&\label{align:refinement_approach:bvsdiv:simple:divm1}\\
        -y < x < y \implies
        &ab_{\texttt{bvsdiv}}\left(x,y\right) \doteq 0&\label{align:refinement_approach:bvsdiv:simple:divres0}\\
\end{flalign}
The first assertion \ref{align:refinement_approach:bvsdiv:simple:div0} implements the SMT-LIB standard for divisions by zero.
The other assertions cover various simple to solve cases of division with \ref{align:refinement_approach:bvsdiv:simple:divm1} also covering the overflow case mentioned above (this is because $-(1\circ 0^{w-1})=1\circ 0^{w-1}$).
Furthermore we can once again make use of cases where $y$ is a power of two
by asserting that for all $i\in\llbracket 1,w \rrbracket$:
\begin{flalign}
    \bigwedge\limits_{j \neq i} \neg x\left[j\right] \land x\left[i\right] \implies \left( ab_\texttt{bvsdiv}\left(x,y\right) \doteq ashr\footnotemark\left( x, i \right)  \right)
    \label{align:refinement_approach:bvsdiv:simple:pow2}
\end{flalign}
\footnotetext{$ashr$ is the arithmetic right shift function}
\paragraph{Completeness}
The approximation is once again complete by Lemma \ref{lemma:refinement_approach:abstraction_scheme:implication} as it is a direct implication of $ab_{\texttt{bvmul}}\left(x,y\right) \doteq \texttt{bvmul}\left(x,y\right)$.

\subsection{Most significant digit based intervals}
In correspondence to the abstraction approach for \texttt{bvmul} we can again make use of the most significant bit of the divisor $y$ for some division $\texttt{bvsdiv}\left(x,y\right)$.
The division problem will first be transformed into its unsigned version:
\begin{flalign*}
    x^+ \doteq \texttt{ITE(}  & x[w-1],&\\
                                & -x&\\
                                & x\texttt{)}&\\
    y^+ \doteq \texttt{ITE(}  & y[w-1],&\\
                                & -y,&\\
                                & y\texttt{)}&\\
    r' \doteq \texttt{ITE(} & x[w-1] \oplus y[w-1],&\\
                                & -udiv(x^+,y^+), &\\
                                & udiv(x^+,y^+) \texttt{)}&\\
\end{flalign*}
Just like for \texttt{bvmul} we then assert that:
\[
    ab_{\texttt{bvsdiv}}\left(x,y\right) \doteq r'
\]
So that one can then reason about $r^+\doteq udiv(x^+,y^+)$:
\begin{flalign*}
    lower(a, b, n)\coloneqq&
    \begin{cases}
        0 & n=0\\
        \texttt{ITE(} msd(b,n), ashr\left(a, n+1\right), lower(a, b, n-1) \texttt{)} & else
    \end{cases}
\\
    upper(a, b, n)\coloneqq&
    \begin{cases}
        a & n=0\\
        \texttt{ITE(} msd(b,n), ashr\left(a, n\right), upper(a, b, n-1) \texttt{)} & else\\
    \end{cases}
\\
    &lower(x^+,y^+,w) \leq r^+ \leq upper(x^+,y^+,w)
\end{flalign*}
This assertion defines an interval for the value of $r^+$ (and through $r^+$ for the value of $ab_{\texttt{bvsdiv}}\left(x,y\right)$) depending on the most significant digit of $y$.

\paragraph{Completeness} The completeness of this abstraction is once again a direct result of the formulae above being an implication of $ab_{\texttt{bvsdiv}}\left(x,y\right) \doteq \texttt{bvsdiv}\left(x,y\right)$.

\subsection{Relations to other functions}
Due to the difficulties of overflows and relation assertions explained in \ref{subsec:refinement_approach:bvmul:relations} once again double bitwidth variables $x_2$ and $y_2$ will be used in the following assertions\footnote{These variables are once again sign extended}.
Note however that as explained earlier the division itself only overflows in a single case already covered in \ref{subsec:refinement_approach:bvsdiv:simple}.\\
For divison the following two assertions are being added (again in accordance with the C standard):
\begin{flalign*}
    ab_{\texttt{bvsdiv}}\left(x,y\right) \doteq& ab_{\texttt{bvsrem}}\left(x_2,y_2\right)\\
    x_2 \doteq& ab_{\texttt{bvmul}}\left( ab_{\texttt{bvsdiv}}\left(x_2,y_2\right), y_2 \right) + ab_{\texttt{bvsrem}}\left(x_2,y_2\right)
\end{flalign*}
\paragraph{Completeness} The proof is entirely parallel to \ref{subsec:refinement_approach:bvmul:relations}.

\subsection{Full division}
In a last step (also parallel to \texttt{bvmul}) division is added interval by interval as explained in \ref{subsec:refinement_approach:bvmul:fullmul} for the multiplication case.
In this case the intervals are based on the value of the dividend $x$.
Just as for \texttt{bvmul} soundness of this abstraction scheme is a direct consequence of the assertions made in this step.

\section{Abstracting \texttt{bvsrem}}
Due to its rareness in benchmarks\footnote{On the one hand its rareness makes it harder to evaluate the performance of abstractions on the other hand abstractions are less likely to have a big impact on the overall performance of the solver.} only a single abstraction layer has been added for this function.
Once again with double bitwidth as explained in \ref{subsec:refinement_approach:bvmul:relations} we assert the relations between \texttt{bvsrem} and other functions:
\begin{flalign*}
    ab_{\texttt{bvsrem}}\left(x,y\right) \doteq& ab_{\texttt{bvsrem}}\left(x_2,y_2\right)\\
    x_2 \doteq& ab_{\texttt{bvmul}}\left( ab_{\texttt{bvsdiv}}\left(x_2,y_2\right), y_2 \right) + ab_{\texttt{bvsrem}}\left(x_2,y_2\right)
\end{flalign*}
In the following refinement step the full remainder constraint is added:
\[
    ab_{\texttt{bvsrem}}\left(x,y\right) \doteq \texttt{bvsrem}\left(x,y\right)
\]
The proof of completeness for the first abstraction is once again in parallel to \ref{subsec:refinement_approach:bvmul:relations}.
The proof of soundness of the overall abstraction scheme for \texttt{bvsrem} is left as an exercise to the reader\footnote{A truly simple one as a matter of fact.}.