\chapter{Related Work}
\label{ch:related_work}
\todo{mkb: Generell: Chapter 2 groß wenn Name von Kaptiel siehe oben das gleiche gilt für Figure, Table etc. Zweiter genereller Punkt den ich ab hier nicht mehr markiere: ... ,we.}
While bit blasting (as described in chapter \ref{ch:preliminaries}) is the predominant approach for solving the \texttt{QF\_BV} theory and related theories, a multitude of techniques are being combined today in order to avoid bitblasting entire instances.
In this chapter we give an overview of some of those techniques based on abstraction refinement.

\section{Counterexample-guided abstraction refinement (CEGAR)}
Counterexample-guided abstraction refinement (CEGAR) was first proposed in the field of software verification for the problem of verifying whether a given program $P$ adhears to some specification $\psi$ \cite{CEGAR}.\\
Given some program $P$ containing variables $V=\{v_1,\dots,v_n\}$ in domains $D_{v_1},\dots,D_{v_n}$ the set $D=D_{v_1}\times\dotsi\times D_{v_n}$ is the set of states of $P$. Let $p$ be some predicate, then $\text{Atoms}\left(p\right)$ is the set of atomic formulae in $p$ and $\text{Atoms}\left(P\right)$ is the set of atomic formulae in $P$. If some program state $d\in D$ satisfies some predicate $p$ we write $d\vDash p$. A program defined this way can be directly transformed into a labeled Kripke-Structure defined as $\mathcal{M}=\left(S,I,R,L\right)$ with $S=D$, $I\subseteq D$, $R \subseteq S \times S$, $L\colon S \to 2^{\text{Atoms}\left(P\right)}$ where $L\left(d\right) = \{ f \in \text{Atoms}\left(P\right) \mid d \vDash f \}$. The objective is then to compute whether $\mathcal{M}\vDash\psi$, that is, whether the $P$'s Kripke-Structure $\mathcal{M}$ satisfies the specification $\psi$.
\paragraph{Abstractions}
An abstraction in the CEGAR sense is a surjection $h\colon D \to \hat{D}$. An abstraction $h$ induces an equivalence relation on the set $D$ of program states with $d \equiv_h e$ iff $h\left(d\right) = h\left(e\right)$.  \todo{mkb: daher ist es in dem sonst gängingen Sprachgebrauch der Arbeit eine under-approximation korrekt? Wenn ja fände ich einen Nebensatz mit der Info hier ganz schön.} Given a Kripke-Structure $\mathcal{M}$ and an abstraction $h$ the \textit{abstracted Kripke-Structure} $\hat{\mathcal{M}} = \left(\hat{S},\hat{I},\hat{R},\hat{L}\right)$ is defined through:
\begin{itemize}
    \item $\hat{S} = \hat{D}$
    \item $\hat{d} \in \hat{I} \iff \exists d \in I\colon h\left(d\right) = \hat{d}$
    \item $\hat{R}\left(\hat{d_1},\hat{d_2}\right) \iff \exists d_1,d_2 \in D\colon h\left(d_1\right) = \hat{d_1} \land h\left(d_2\right) = \hat{d_2} \land R\left(d_1, d_2\right)$
    \item $\hat{L}\left(\hat{d}\right)=\bigcup\limits_{h\left(d\right)=\hat{d}} L\left(d\right)$
\end{itemize}

\begin{theorem}
    \label{theorem:related_work:cegar:sat}
    Let $h$ be an abstraction and $\psi$ some specification.
    Given that for every atomic formula $f$ in $\psi$ and for all $d,d' \in D$ the property $\left(d \equiv_h d'\right) \implies \left( d \vDash f \Leftrightarrow d' \vDash f \right)$ holds (we call this \enquote{$f$ respects $h$}), then:\\
    \begin{itemize}
        \item[(i)] $\hat{L}\left(\hat{d}\right)$ is consistent for all abstract states $\hat{d}$ in $\hat{M}$
        \item[(ii)] $\hat{\mathcal{M}}\vDash\psi \implies \mathcal{M} \vDash \psi$
    \end{itemize}
\end{theorem}
Do note that while correctness (as defined by $\psi$) of the abstract model $\hat{\mathcal{M}}$ implies correctness of the original model $\mathcal{M}$ a model might still be correct if $\hat{\mathcal{M}} \nvDash \psi$.

\paragraph{Initial abstraction}
Upon initialization of the solving process an initial abstraction $h$ is generated by grouping the variables $V=\{v_1,\dots,v_n\}$ into disjoint variable clusters $V = VC_1 \Dot{\cup} \dotsi \Dot{\cup} VC_n$. A variable cluster containing variable $v_i$ contains any other variables $v_j$ which appear in the same atomic formulae as $v_i$ - this induces an equivalence relation relation on the variables. For each variable cluster $VC_i=\{v_{i_1},\dots,v_{i_k}\}$ an abstraction is defined through:
\begin{flalign*}
   & h_i\left(d_1,\dots,d_k\right) = h_i\left(e_1,\dots,e_k\right)
    \text{ iff for all atomic formulae $f$}\\
    &\left(d_1,\dots,d_k\right) \vDash f \iff \left(e_1,\dots,e_k\right) \vDash f
\end{flalign*}

\paragraph{Handling counterexamples}
If the solver returns $\hat{\mathcal{M}} \vDash \psi$, Theorem \ref{theorem:related_work:cegar:sat} tells us that $\mathcal{M} \vDash \psi$. Otherwise the solver is assumend to return a counter example that can be checked on its correctness. More precisely it is necessary to check whether the counterexample is only possible in the abstracted structure $\hat{\mathcal{M}}$ or not. If the counterexample is caused by the abstraction and is therefore \textit{spurious}, a refinement step is made detailing the previous abstractions and the solver will run once again on this less-abstracted version of the problem \cite{CEGAR} until the counterexample is either correct or $\hat{\mathcal{M}}\vDash\psi$.
\paragraph{}
Since its introduction this approach of abstracting and refining has been used in wide range of applications including software verification \cite{CEGAR}, relational learning \cite{CEGAR-Relational-Learning} and SAT based planning \cite{CEGAR-Planning} as the core idea can be reused in most fields concerned with solving logic formulae.


%\section{STP}

\section{Boolector and Lemmas on Demand}
\label{par:related_work:boolector}
With Boolector \cite{Brummayer-Biere2009_Chapter_BoolectorAnEfficientSMTSolverF} another \todo{mkb: "another ... over-approximation", mein Verständnis nach war CEGAR under-approx oder?} approach to over-approximation called \textit{Lemmas on Demand} was introduced to SMT solving. Boolector uses this extreme variant of lazy SMT solving for both solving array theory problems \cite{p6-brummayer} and uninterpreted function theory problems \cite{NiemetzPreinerBiere-FMCAD14}.
This is particularly interesting as Boolector interleaves over- and under-approximation techniques as can be seen in figure \ref{fig:related_work:boolector:scheme}.
Additionally Boolector makes heavy use of rewriting to solve easy bitvector theory instances - sometimes without using a SAT solver back-end at all.
\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[node distance=3cm]
    \tikzstyle{io} = [minimum width=3cm, minimum height=1cm, text centered]
    \tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black]
    \tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black]
    \tikzstyle{arrow} = [thick,->,>=stealth]
    
    \node (in) [io] {Array formula};
    \node (overapprox) [process, below of=in] {Replace UF and arrays by over-approximation};
    \node (underapprox) [process, below of=overapprox] {Add under-approximation clauses C};
    
    
    \node (issat) [decision, below of=underapprox] {SAT?};
    \node (isspurious) [decision, left of=issat,xshift=-2cm] {spurious?};
    \node (cused) [decision, right of=issat,xshift=2cm] {C used?};
    
    \node (satout) [io, above of=isspurious] {\texttt{sat}};
    \node (unsatout) [io, below of=cused] {\texttt{unsat}};
    
    \node (addlemma) [process, below of=issat] {Add lemma};
    
    \draw [arrow] (in) -- (overapprox);
    \draw [arrow] (overapprox) -- node[anchor=west] {Encode to CNF} (underapprox);
    \draw [arrow] (underapprox) -- node[anchor=west] {Call SAT solver} (issat);
    \draw [arrow] (issat) -- node[anchor=south] {YES} (isspurious);
    \draw [arrow] (issat) -- node [anchor=south] {NO} (cused);
    \draw [arrow] (isspurious) -- node[anchor=east] {NO} (satout);
    \draw [arrow] (isspurious) |- node[anchor=east,pos=0.25] {YES} node[anchor=north, pos=0.7] {Refine over-approx.} (addlemma);
    \draw [arrow] (addlemma) -- node[anchor=west] {Call SAT solver} (issat);
    
    \draw [arrow] (cused) -- node[anchor=west] {NO} (unsatout);
    
    \draw [arrow] (cused) |- node[anchor=west,pos=0.2] {YES} node[anchor=south,pos=0.6,align=center] {Refine\\under-approx.} (underapprox);
    
    \end{tikzpicture}
    \caption{Interleaving over- and under-approximation techniques in Boolector as presented in \cite{Brummayer-PhD}}
    \label{fig:related_work:boolector:scheme}
\end{figure}

\paragraph{Rewriting}
SMT formulae passed to Boolector are rewritten in 3 levels \cite{Brummayer-Biere2009_Chapter_BoolectorAnEfficientSMTSolverF}. In a first step very basic logic rules are applied during formula construction. In a second step global term substitution is performed on a topologically sorted DAG representation of the formula set. In a third and last step arithmetic normalization is performed.

\paragraph{Under-Approximation}
Boolector makes use of under-approximation on the CNF level by adding assumptions to the SAT solver instance \cite{Brummayer-PhD}. Boolector restricts the \textit{effective bitwidth} of a given bitvector to a smaller size which is then sign extended (or sometimes zero extended) to reach the original bitsize. Using a newly introduced assumption variable $e$ this behaviour can be (de)activated as needed for each run through the SAT solvers assumption interface by adding/removing an activation clause $e$ or $\neg e$. The additional constraints reduce the search-space size and thereby help to potentially speed up the solver's search. Furthermore, the additional constraints lead the solver towards smaller, usually better understandable models.

\paragraph{Lemmas on Demand}
Boolector uses over-approximation for solving the array \cite{p6-brummayer} and uninterpreted function (UF) theories \cite{PreinerNiemetzBiere-DIFTS13}. We will explain the idea behind this extreme variant of lazy SMT solving based on the uninterpreted function case.
\par
For its initial abstraction every UF applications is replaced by a fresh bitvector variable. Afterwards the problem can be eagerly encoded as a SAT problem. If the SAT solver returns unsatisfiability the original problem is unsatisfiable, too. If on the other hand, the SAT solver returns a satisfying interpretation $\mathcal{I}$, we must now check whether the corresponding SMT interpretation $t\left(\mathcal{I}\right)$ is consistent with the uninterpreted function's theory. More precisely, we must check whether for every function $f$ its applications $f\left(\overline{x_1}\right),\dots,f\left(\overline{x_{m_{f}}}\right)$ are consistent with the (\ref{eq:preliminaries:smt:euf}) axiom.
\par
If it is found that for two UF applications $t=f\left(a_1,\dots,a_n\right)$ and $s=f\left(b_1,\dots,b_n\right)$
the axiom is not respected (i.e., $a_i=b_i$ for all $i\in\llbracket1,n\rrbracket$ but $s\neq t$) an additional lemma encoding this constraint will be added. For this the shortest paths $p^s$ and $p^t$ from the function application $s$ (and $t$) to $f$ are calculated and all \textit{ite} conditions $c_0^s,\dots,c_j^s$ ($c_0^t,\dots,c_k^t$) on the paths evaluating to $\blacksquare$ under $t\left(\mathcal{I}\right)$ as well as all \textit{ite} conditions $d_0^s,\dots,d_l^s$ ($d_0^t,\dots,d_m^t$) on the paths evaluating to $\square$ under $t\left(\mathcal{I}\right)$ are collected. Using this information the following lemma is added to the SAT instance:
\todo{mkb: Ich verstehe hier nicht woher die ite conditions kommen bzw. verstehe die Notation an dieser Stelle auch nicht.}
\[
\left(\bigwedge\limits_{i=0}^{j}c_i^s \land \bigwedge\limits_{i=0}^{k}c_i^t \land \bigwedge\limits_{i=0}^{l} \neg d_i^s \land \bigwedge\limits_{i=0}^{m} \neg d_i^t \land \bigwedge\limits_{i=0}^{n} a_i=b_i \right) \implies s=t
\]
\todo{mkb: Punkt nach der Formel, da dies Satzende ist}
This approach proved very effective in solving both the UF theory as well as the array theory.
For its extension to arrays the reader is referred to \cite{p6-brummayer}.
While not relevant for this work \cite{PreinerNiemetzBiere-DIFTS13} also explains how lemmas on demand can be used for lambda expressions.
The technique can be further optimized by only refining those UF applications which are actually relevant for the current satisfying counterexample \cite{NiemetzPreinerBiere-FMCAD14}.

\paragraph{Overflow Detection}
Boolector implements efficiently encoded predicates for overflow detection in addition, substraction, multiplication and division \cite{Brummayer-PhD}. Let $L\left(a\right)$ be the number of leading bits (zero or one) for some bitvector $a$. Given a signed multiplication instance $r=a*b$ \todo{mkb: where a and b are bitvectors of size n} an overflow occurs iff $L\left(a\right) + L\left(b\right) < n$ or $r\left[n\right] \oplus r\left[n-1\right]$ \cite{schulteGokMulOv}. This result allows to check a signed multiplication for overflow issues by only calculating the first $n+1$ multiplication bits in contrast to $2n$ bits for the naive encoding. Similar predicates are available for all basic arithmetic operations.

\section{UCLID}
\textsc{UCLID} \cite{Bryant2007_Chapter_DecidingBit-VectorArithmeticWi-UCLID} was one of the SMT solvers which introduced the interleaving of over- and under-Approximations using abstractions. Given an input formula $\phi$ the \textsc{UCLID} solver constructs an SMT under-approximation $\underline{\phi}$. The formula is usually generated by restricting variables to their sign-extended versions of a smaller bit size as previously seen in Boolector (i.e., $v_nv_{n-1}\dotsi v_1$ becomes $v_mv_m\dotsi v_m v_{m-1}\dotsi v_1$.) \todo{mkb: with $m<n$, warum, stehen dort am Anfang direkt zwei $v_m$, es kann auch einfach nur $v_m, v_m, v_{m-1}, \dots$ sein oder?} This formula $\underline{\phi}$ is then eagerly encoded and passed to a SAT solver. The SAT solver can produce one of two outcomes:

\paragraph{SAT} In case the SAT solver finds a model such that $t\left(\mathcal{I}\right)\vDash\underline{\phi}$ the solver returns \texttt{sat} as $t\left(\mathcal{I}\right)\vDash\phi$. In this case \textsc{UCLID} can potentially speed up the SAT solver's runtime due to the reduced search space when solving the under-approximation $\underline{\phi}$

\paragraph{UNSAT} In case the SAT solver returns an unsatisfiability result, \textsc{UCLID} uses the UNSAT-Core returned by the solver to extract the the formulae which produced the contradiction. Only based on these formulae (thereby leaving out all formulae of the instance that are not part of the contradiction) an over-approximation $\overline{\phi}$ is built. In contrast to $\underline{\phi}$ this over-approximation does in no way restrict the bitwidth of the input variables. \todo{mkb: persönliches interesse: wie funktioniert das? Ich stelle mir eine SAT Formel vor und dort sind für jedes bit also abhängig von der breite eine Variable, wenn man die Länge nicht festlegt wie legt man dort variablen an?} $\overline{\phi}$ is then passed to the SAT solver. If the SAT solver still returns unsatisfiability \textsc{UCLID} returns \texttt{unsat}. In case the solver returns satisfiability the under-approximation $\underline{\phi}$ is refined (usually increasing the bitwidth) and a second iteration begins.
\par
For unsatisfiable instances \textsc{UCLID} takes advantage of cases where a small number of formulae can produce the contradiction and makes the SAT-solver only look at these formulae thereby potentially improving the solver's performance.
